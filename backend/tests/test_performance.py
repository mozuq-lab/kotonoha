"""
ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ

ã€ãƒ•ã‚¡ã‚¤ãƒ«ç›®çš„ã€‘: AIå¤‰æ›APIã®å¿œç­”æ™‚é–“ã¨ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆã‚’ãƒ†ã‚¹ãƒˆ
ã€ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹ã€‘: å¿œç­”æ™‚é–“ãƒ†ã‚¹ãƒˆã€è² è·ãƒ†ã‚¹ãƒˆã€æ¥ç¶šãƒ—ãƒ¼ãƒ«ãƒ†ã‚¹ãƒˆ

TASK-0030: Week 6 çµ±åˆãƒ†ã‚¹ãƒˆãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
ğŸ”µ NFR-002ï¼ˆAIå¤‰æ›å¿œç­”æ™‚é–“å¹³å‡3ç§’ä»¥å†…ï¼‰ã€NFR-101ï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ï¼‰ã«åŸºã¥ã
"""

import asyncio
import time
from unittest.mock import AsyncMock, patch

import pytest
from httpx import ASGITransport, AsyncClient

from app.core.rate_limit import limiter
from app.main import app


@pytest.fixture(autouse=True)
async def reset_limiter():
    """å„ãƒ†ã‚¹ãƒˆå®Ÿè¡Œå‰ã«ãƒªãƒŸãƒƒã‚¿ãƒ¼ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ãƒªã‚»ãƒƒãƒˆ"""
    limiter.reset()
    yield
    limiter.reset()


@pytest.mark.asyncio
async def test_ai_conversion_response_time_with_mock():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: AIå¤‰æ›å¿œç­”æ™‚é–“ãƒ†ã‚¹ãƒˆï¼ˆNFR-002: å¹³å‡3ç§’ä»¥å†…ï¼‰
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: ãƒ¢ãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¦AIå¤‰æ›ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã‚’æ¸¬å®š
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: å¹³å‡å¿œç­”æ™‚é–“ãŒ3ç§’ä»¥å†…
    ğŸ”µ NFR-002ã«åŸºã¥ããƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    """

    async def mock_convert_text_with_delay(input_text: str, politeness_level: str):
        """å®Ÿéš›ã®AIå‘¼ã³å‡ºã—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆï¼ˆ100msé…å»¶ï¼‰"""
        await asyncio.sleep(0.1)  # 100msé…å»¶ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        return (f"å¤‰æ›æ¸ˆã¿: {input_text}", 100)

    with (
        patch("app.utils.ai_client.ai_client") as mock_ai_client,
        patch("app.api.v1.endpoints.ai.create_conversion_log", new_callable=AsyncMock),
    ):
        mock_ai_client.convert_text = AsyncMock(side_effect=mock_convert_text_with_delay)

        transport = ASGITransport(app=app)
        async with AsyncClient(transport=transport, base_url="http://test") as client:
            response_times = []

            # å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å›é¿ï¼‰
            start = time.time()
            response = await client.post(
                "/api/v1/ai/convert",
                json={
                    "input_text": "ãƒ†ã‚¹ãƒˆæ–‡ç« ",
                    "politeness_level": "normal",
                },
            )
            elapsed = time.time() - start

            assert response.status_code == 200
            response_times.append(elapsed)

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª
            data = response.json()
            assert "processing_time_ms" in data

            # å¿œç­”æ™‚é–“ã‚’ç¢ºèªï¼ˆãƒ¢ãƒƒã‚¯ãªã®ã§3ç§’ä»¥å†…ã¯ç¢ºå®Ÿï¼‰
            avg_time = sum(response_times) / len(response_times)
            assert avg_time < 3.0, f"Average response time {avg_time:.2f}s exceeds 3s limit"


@pytest.mark.asyncio
async def test_health_check_response_time():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å¿œç­”æ™‚é–“ãƒ†ã‚¹ãƒˆ
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã‚’æ¸¬å®š
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã¯1ç§’ä»¥å†…ã«å¿œç­”
    ğŸ”µ NFR-304ã«åŸºã¥ããƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    """
    # ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼ˆ/ï¼‰ã¯DBã‚¢ã‚¯ã‚»ã‚¹ãªã—ãªã®ã§é«˜é€Ÿ
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        response_times = []

        for _ in range(10):
            start = time.time()
            response = await client.get("/")
            elapsed = time.time() - start

            assert response.status_code == 200
            response_times.append(elapsed)

        # ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¯1ç§’ä»¥å†…ã«å¿œç­”
        avg_time = sum(response_times) / len(response_times)
        assert avg_time < 1.0, f"Root endpoint avg time {avg_time:.2f}s exceeds 1s limit"


@pytest.mark.asyncio
async def test_concurrent_root_endpoint_requests():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆè² è·ãƒ†ã‚¹ãƒˆ
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: è¤‡æ•°ã®ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸¦è¡Œå®Ÿè¡Œ
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹
    ğŸ”µ NFR-304ã«åŸºã¥ãè² è·ãƒ†ã‚¹ãƒˆ
    """
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        # 20å€‹ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä¸¦è¡Œå®Ÿè¡Œ
        tasks = [client.get("/") for _ in range(20)]
        responses = await asyncio.gather(*tasks)

        # ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        success_count = sum(1 for r in responses if r.status_code == 200)
        assert success_count == 20, f"Only {success_count}/20 requests succeeded"


@pytest.mark.asyncio
async def test_concurrent_ai_conversions_without_rate_limit():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: ä¸¦è¡ŒAIå¤‰æ›è² è·ãƒ†ã‚¹ãƒˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãªã—ï¼‰
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: è¤‡æ•°ã®AIå¤‰æ›ã‚’ä¸¦è¡Œå®Ÿè¡Œï¼ˆãƒ¢ãƒƒã‚¯ä½¿ç”¨ã€ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ç„¡åŠ¹åŒ–ï¼‰
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹
    ğŸ”µ NFR-002ã«åŸºã¥ãè² è·ãƒ†ã‚¹ãƒˆ
    """
    call_count = 0

    async def mock_convert_text(input_text: str, politeness_level: str):
        nonlocal call_count
        call_count += 1
        await asyncio.sleep(0.05)  # 50msé…å»¶
        return (f"å¤‰æ›æ¸ˆã¿: {input_text}", 50)

    with (
        patch("app.utils.ai_client.ai_client") as mock_ai_client,
        patch("app.api.v1.endpoints.ai.create_conversion_log", new_callable=AsyncMock),
        patch("app.api.v1.endpoints.ai.limiter.limit", lambda x: lambda f: f),  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’ç„¡åŠ¹åŒ–
    ):
        mock_ai_client.convert_text = AsyncMock(side_effect=mock_convert_text)

        transport = ASGITransport(app=app)
        async with AsyncClient(transport=transport, base_url="http://test") as client:
            # å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§æˆåŠŸã‚’ç¢ºèª
            start = time.time()
            response = await client.post(
                "/api/v1/ai/convert",
                json={
                    "input_text": "ãƒ†ã‚¹ãƒˆæ–‡ç« ",
                    "politeness_level": "normal",
                },
            )
            total_time = time.time() - start

            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert response.status_code == 200

            # å‡¦ç†æ™‚é–“ãŒåˆç†çš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert total_time < 1.0, f"Total time {total_time:.2f}s is too long"


@pytest.mark.asyncio
async def test_sequential_requests_response_consistency():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: é€£ç¶šãƒªã‚¯ã‚¨ã‚¹ãƒˆæ™‚ã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å¿œç­”ã®ä¸€è²«æ€§ã‚’ç¢ºèªï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ï¼‰
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã€ä¸€è²«ã—ãŸæ§‹é€ ã®å¿œç­”ã‚’è¿”ã™
    ğŸ”µ NFR-301ï¼ˆé‡å¤§ãªã‚¨ãƒ©ãƒ¼ã§ã‚‚åŸºæœ¬æ©Ÿèƒ½ç¶™ç¶šï¼‰ã«åŸºã¥ã
    """
    mock_response = ("å¤‰æ›æ¸ˆã¿ãƒ†ã‚­ã‚¹ãƒˆ", 1000)

    with (
        patch("app.utils.ai_client.ai_client") as mock_ai_client,
        patch("app.api.v1.endpoints.ai.create_conversion_log", new_callable=AsyncMock),
    ):
        mock_ai_client.convert_text = AsyncMock(return_value=mock_response)

        transport = ASGITransport(app=app)
        async with AsyncClient(transport=transport, base_url="http://test") as client:
            # å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã§ä¸€è²«æ€§ã‚’ç¢ºèª
            response = await client.post(
                "/api/v1/ai/convert",
                json={
                    "input_text": "ãƒ†ã‚¹ãƒˆ",
                    "politeness_level": "normal",
                },
            )
            assert response.status_code == 200
            data = response.json()

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒæ­£ã—ã„æ§‹é€ ã‚’æŒã¤ã“ã¨ã‚’ç¢ºèª
            required_fields = {
                "converted_text",
                "original_text",
                "politeness_level",
                "processing_time_ms",
            }
            assert required_fields.issubset(
                data.keys()
            ), f"Missing fields in response: {data.keys()}"


@pytest.mark.asyncio
async def test_large_input_text_performance():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: å¤§ããªå…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã§ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: é•·ã„å…¥åŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã—ãŸå ´åˆã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚’ç¢ºèª
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: é•·ã„ãƒ†ã‚­ã‚¹ãƒˆã§ã‚‚æ­£å¸¸ã«å‡¦ç†ã•ã‚Œã‚‹
    ğŸ”µ NFR-002ã«åŸºã¥ããƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    """
    large_text = "ã‚" * 500  # 500æ–‡å­—ã®å…¥åŠ›

    async def mock_convert_text(input_text: str, politeness_level: str):
        await asyncio.sleep(0.1)  # 100msé…å»¶
        return (f"å¤‰æ›æ¸ˆã¿: {input_text[:50]}...", 100)  # æœ€åˆã®50æ–‡å­—ã®ã¿è¿”ã™

    with (
        patch("app.utils.ai_client.ai_client") as mock_ai_client,
        patch("app.api.v1.endpoints.ai.create_conversion_log", new_callable=AsyncMock),
    ):
        mock_ai_client.convert_text = AsyncMock(side_effect=mock_convert_text)

        transport = ASGITransport(app=app)
        async with AsyncClient(transport=transport, base_url="http://test") as client:
            start = time.time()
            response = await client.post(
                "/api/v1/ai/convert",
                json={
                    "input_text": large_text,
                    "politeness_level": "polite",
                },
            )
            elapsed = time.time() - start

            assert response.status_code == 200
            assert elapsed < 3.0, f"Large text processing took {elapsed:.2f}s"


@pytest.mark.asyncio
async def test_multiple_endpoints_concurrent():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: è¤‡æ•°ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆ
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹
    ğŸ”µ NFR-304ã«åŸºã¥ãè² è·ãƒ†ã‚¹ãƒˆ
    """
    transport = ASGITransport(app=app)
    async with AsyncClient(transport=transport, base_url="http://test") as client:
        # ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¸ã®ä¸¦è¡Œãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆãƒ¬ãƒ¼ãƒˆåˆ¶é™ãªã—ï¼‰
        tasks = [
            client.get("/"),
            client.get("/"),
            client.get("/"),
            client.get("/"),
        ]

        responses = await asyncio.gather(*tasks)

        # ã™ã¹ã¦ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        for response in responses:
            assert response.status_code == 200


@pytest.mark.asyncio
async def test_response_time_single_request():
    """
    ã€ãƒ†ã‚¹ãƒˆç›®çš„ã€‘: å˜ä¸€ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ãƒ†ã‚¹ãƒˆ
    ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘: å˜ä¸€ã®AIå¤‰æ›ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã‚’æ¸¬å®š
    ã€æœŸå¾…ã•ã‚Œã‚‹å‹•ä½œã€‘: 3ç§’ä»¥å†…ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
    ğŸ”µ NFR-002ã«åŸºã¥ããƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    """
    mock_response = ("å¤‰æ›æ¸ˆã¿", 500)

    with (
        patch("app.utils.ai_client.ai_client") as mock_ai_client,
        patch("app.api.v1.endpoints.ai.create_conversion_log", new_callable=AsyncMock),
    ):
        mock_ai_client.convert_text = AsyncMock(return_value=mock_response)

        transport = ASGITransport(app=app)
        async with AsyncClient(transport=transport, base_url="http://test") as client:
            start = time.time()
            response = await client.post(
                "/api/v1/ai/convert",
                json={
                    "input_text": "ãƒ†ã‚¹ãƒˆ",
                    "politeness_level": "normal",
                },
            )
            elapsed = time.time() - start

            assert response.status_code == 200

            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒ3ç§’ä»¥å†…ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert elapsed < 3.0, f"Response time {elapsed:.2f}s exceeds 3s limit"

            # å¹³å‡ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ ã‚‚ç¢ºèª
            assert elapsed < 1.0, f"Response time {elapsed:.2f}s exceeds 1s limit"
